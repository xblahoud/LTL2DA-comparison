{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from ltlcross_runner import LtlcrossRunner\n",
    "from tools_hier import get_tools, ltl3dra_tools, full_tools, tool_order\n",
    "from evaluation_utils import sort_by_tools, split_cols\n",
    "import pandas as pd\n",
    "import spot\n",
    "spot.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of LTL to deterministic automata translators \n",
    "\n",
    "$\\newcommand{\\F}{\\mathsf{F}}\\newcommand{\\G}{\\mathsf{G}}\\newcommand{\\U}{\\mathsf{U}}\\newcommand{\\X}{\\mathsf{X}}$\n",
    "## Tools\n",
    "We have \n",
    "* tools that translate \\[fragments\\] of LTL into (generalized) Rabin automata:\n",
    " - [Rabinizer 3.1](https://www7.in.tum.de/~kretinsk/rabinizer3.html)\n",
    " - [Rabinizer 4](https://www7.in.tum.de/~kretinsk/rabinizer4.html)\n",
    " - [LTL3DRA](https://sourceforge.net/projects/ltl3dra/) v.0.2.6 \\[LTL$\\smallsetminus\\G$($\\U\\X$)\\]\n",
    "* tools that chain translation of LTL into cut-deterministic BÃ¼chi automata (aka LDBA) or into deterministic Rabin automata with a construction that create deterministic parity automaton. They avoid Safra-like determinization. Both are from the [owl/Rabinizer4 library](https://www7.in.tum.de/~kretinsk/rabinizer4.html)\n",
    " - ltl2dpa --mode=ldba\n",
    " - ltl2dpa --mode=rabinizer (relies on transition-based index appearance record)\n",
    "* tools that perform Safra-based determinization of N\\[G\\]BA into {Rabin/Parity} automata that use intermediete NBA\n",
    " - [ltl2dstar](http://ltl2dstar.de) \\[NBA only\\] {Rabin)}\n",
    " - autfilt from [Spot](https://spot.lrde.epita.fr/) 2.5 {parity}\n",
    " - here we use the following LTL2TGBA/LTL2NBA translators:\n",
    "   - ltl2tgba from [Spot](https://spot.lrde.epita.fr/) 2.5\n",
    "   - [LTL3BA](https://sourceforge.net/p/ltl3ba/) v. 1.1.3; we use LTL3BA in two settings:\n",
    "     - `ltl3ba` {LTL3BA}\n",
    "     - `ltl3ba -d` {LTL3BAd} which prefer more deterministic automata to smaller ones\n",
    " - we further use experimentaly for autfilt the LTL to Emerson-Lei automata translator\n",
    "   - [LTL3TELA](https://github.com/jurajmajor/ltl3tela) v.1.1.1\n",
    "* Safra's based determinization into deterministic parity automata that uses information about the LTL formula\n",
    " - `ltl2tgba -DG` from [Spot](https://spot.lrde.epita.fr/) 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners = {}\n",
    "cols=[\"states\",\"transitions\",\"acc\",\"time\",\"nondet_states\"]\n",
    "for source in ('literature','random'):\n",
    "    for t in ('full','ltl3dra'):\n",
    "        name = '{}_{}'.format(source,t)\n",
    "        tools = full_tools if t=='full' else ltl3dra_tools\n",
    "        runners[name] = \\\n",
    "            LtlcrossRunner(tools,\\\n",
    "                    res_filename='data/{}.csv'.format(name),\\\n",
    "                    formula_files=['formulae/{}.ltl'.format(name)],\\\n",
    "                    cols=cols)\n",
    "\n",
    "name = 'random_fg'\n",
    "tools = ltl3dra_tools\n",
    "runners[name] = LtlcrossRunner(tools,\\\n",
    "                    res_filename='data/{}.csv'.format(name),\\\n",
    "                    formula_files=['formulae/{}.ltl'.format(name)],\\\n",
    "                    cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, r in runners.items():\n",
    "    print('{}: Working on {}'.format(datetime.now().strftime('[%d.%m.%Y %T]'),name))\n",
    "    r.name = name\n",
    "    r.parse_results()\n",
    "    r.na_incorrect()\n",
    "    r.orig_count = len(r.values)\n",
    "    r.clean_count = len(r.values.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, r in runners.items():\n",
    "    print('The benchmark {} started with {} formulae and has valid data for {} formulae'.format(name,r.orig_count,r.clean_count))\n",
    "    r.errors = {}\n",
    "    for e in ['timeout', 'parse error', 'incorrect', 'crash', 'no output']:\n",
    "        s = r.get_error_count(e).sum()\n",
    "        if not pd.isna(s):\n",
    "            r.errors[e] = r.get_error_count(e).sum()\n",
    "    s = pd.Series(r.errors, name='count')\n",
    "    s.index.name = 'error type'\n",
    "    display(s.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_runner(self,cols=['states','acc','time'],\n",
    "                   tool_subset=None, split_col_names=True, col_lev_names=None,\n",
    "                   counts = True):\n",
    "    '''Returns a dataframe with rows indexed by tools in\n",
    "    `tool_subset (or `self.tools.keys()`) and columns by\n",
    "    cols. The values are cummulative sums for respective\n",
    "    tool and column.'''\n",
    "    if tool_subset is None:\n",
    "        tool_subset = self.tools.keys()\n",
    "    name = self.name\n",
    "    name = name.replace('ltl3dra','ltl-gux')\n",
    "    if counts:\n",
    "        name = '{} ({})'.format(name,self.clean_count)\n",
    "    col_names = ['{}_{}'.format(name,c) for c in cols]\n",
    "    df = pd.DataFrame(columns=col_names,index=tool_subset)\n",
    "    for col in cols:\n",
    "        df['{}_{}'.format(name,col)] = self.cummulative(col).map(lambda x: '%0.0f' % x)\n",
    "    if split_col_names:\n",
    "        res = split_cols(df,axis=1,symbol='_',names=col_lev_names)\n",
    "    else:\n",
    "        res = df\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(compute_runner(r).head())\n",
    "display(compute_runner(r,split_col_names=False).head())\n",
    "compute_runner(r,col_lev_names=['source','fragment','metric']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "order = [\n",
    "    ('literature','full'),\n",
    "    ('literature','ltl3dra'),\n",
    "    ('random','full'),\n",
    "    ('random','ltl3dra'),\n",
    "    ('random','fg'),\n",
    "]\n",
    "for o in order:\n",
    "    data.append(compute_runner(runners['{}_{}'.format(o[0],o[1])]))\n",
    "res = pd.concat(data,axis=1)\n",
    "res = split_cols(res,axis=0,symbol='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_acc(acc):\n",
    "    acc = acc.replace('TGBA','TGB').replace('NBA','SB')\n",
    "    acc = acc.replace('DPA','DTPA').replace('DTPA','TP')\n",
    "    acc = acc.replace('DSRA','SR').replace('DTGRA','TGR')\n",
    "    return acc.replace('DTELA','TEL').replace('TEL.TP','TEL.TEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_tools(tool):\n",
    "    tool = tool.replace('ltl2dstar(NBA)',\n",
    "                        '\\parbox[c]{1.3cm}{\\centering ltl2dstar NBA}')\n",
    "    tool = tool.replace('Spot',\n",
    "                        '\\rotatebox[origin=c]{90}{Spot (autfilt)}')\n",
    "    tool = tool.replace('R3','Rabinizer 3').replace('R4','Rabinizer 4')\n",
    "    return tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_fragment(fr):\n",
    "    fr = fr.replace('full','full LTL')\n",
    "    fr = fr.replace('ltl-gux','\\LTLGUX')\n",
    "    return fr.replace('fg','\\FG').replace('(','[$').replace(')','$]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_index(df):\n",
    "    i = [(fix_tools(t[0]),t[1],fix_acc(t[2])) for t in df.index.values]\n",
    "    df.index=pd.MultiIndex.from_tuples(i)\n",
    "    ci = [(t[0],fix_fragment(t[1]),t[2]) for t in df.columns.values]\n",
    "    df.columns=pd.MultiIndex.from_tuples(ci)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_type_lines(filename):\n",
    "    cline = '\\midrule'\n",
    "    todo = ['\\multirow{2}{*}{ltl2dpa}','\\multirow{3}{*}{ltl2dstar}']\n",
    "    for rplc in todo:\n",
    "        with open(filename) as f:\n",
    "            lines = f.read().replace(\"{}\".format(rplc),\n",
    "                                     \"{}{}\".format(cline,rplc))\n",
    "        with open(filename,\"w\") as f1:\n",
    "            f1.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lines(filename, end=12):\n",
    "    end = str(end)\n",
    "    todo = [('\\multirow{2}{*}{ltl2dpa}','\\cmidrule{1-'+ end +'}'),\n",
    "     ('& \\multirow{2}{*}{Spot}','\\cmidrule{2-'+ end +'}')]\n",
    "    for rplc, cline in todo:\n",
    "        with open(filename) as f:\n",
    "            lines = f.read().replace(\"{}\".format(rplc),\n",
    "                                     \"{}{}\".format(cline,rplc))\n",
    "        with open(filename,\"w\") as f1:\n",
    "            f1.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_table(filename):\n",
    "    setup = '''\\\\newcolumntype{a}{>{\\\\columncolor{blue!20}}r}\n",
    "\\\\newcolumntype{b}{>{\\\\columncolor{blue!20}}c}\n",
    "\\\\setlength{\\\\aboverulesep}{0pt}\n",
    "\\\\setlength{\\\\belowrulesep}{0pt}\n",
    "\\\\setlength{\\\\extrarowheight}{.75ex}\n",
    "\\\\setlength{\\\\heavyrulewidth}{2pt}\n",
    "\\\\setlength{\\\\lightrulewidth}{1.2pt}\n",
    "\\\\def\\\\high{\\\\cellcolor{darkgreen!40}}\n",
    "'''\n",
    "    with open(filename) as f:\n",
    "        lines = f.read()\n",
    "    lines = fix_header_colors(lines)\n",
    "    lines = lines.replace('cline','cmidrule')\n",
    "    lines = lines.replace('$nan$','---')\n",
    "    # Remove cmidrules in front of midrule\n",
    "    lines = re.sub(r\"(\\\\cmidrule\\{\\d+-\\d+\\}\\n?)+\\\\midrule\", \"\\\\midrule\", lines)\n",
    "    with open(filename,\"w\") as f1:\n",
    "        f1.write(setup + lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heading(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.read()\n",
    "    lines = re.sub(r\"(\\s+)&\\s+&\\s+&\\s+states\", r\"\\1main tool & intermediate & acc & states\", lines)\n",
    "    with open(filename,\"w\") as f1:\n",
    "        f1.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_header_colors(lines):\n",
    "    lines = lines.replace('{c}','{b}',1)\n",
    "    i = lines.find('{c}')\n",
    "    return lines[:i+1] + lines[i+1:].replace('{c}','{b}',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cummulative_to_latex(res,file='cumm.tex',transpose=False):\n",
    "    if transpose:\n",
    "        res = res.T\n",
    "    col_f = 'ccr'\n",
    "    for i in range(len(res.columns)//3):\n",
    "        if i % 2 == 0:\n",
    "            col_f += 'aaa'\n",
    "        else:\n",
    "            col_f += 'rrr'\n",
    "    res = res\n",
    "    res.to_latex(buf=open(file,'w'),multirow=True,escape=False,na_rep='---',float_format=lambda x: '$' + '%0.0f' % x + '$',column_format=col_f,multicolumn_format='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_min(data):\n",
    "    return ['\\high ${:0.0f}$'.format(m) if \n",
    "            m == data.min() else m for m in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_all = sort_by_tools(res,tool_order)\n",
    "shorten_index(sorted_all)\n",
    "sorted_all = sorted_all.astype(float).apply(high_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cummulative_to_latex(sorted_all.random, file='cumm_rand.tex', transpose=False)\n",
    "fix_lines('cumm_rand.tex',12)\n",
    "add_type_lines('cumm_rand.tex')\n",
    "color_table('cumm_rand.tex')\n",
    "make_heading('cumm_rand.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cummulative_to_latex(sorted_all.literature, file='cumm_lit.tex', transpose=False)\n",
    "fix_lines('cumm_lit.tex',9)\n",
    "add_type_lines('cumm_lit.tex')\n",
    "color_table('cumm_lit.tex')\n",
    "make_heading('cumm_rand.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
