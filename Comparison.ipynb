{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "from ltlcross_runner import LtlcrossRunner\n",
    "from tools_hier import get_tools, ltl3dra_tools, full_tools, tool_order\n",
    "import tools_hier\n",
    "from evaluation_utils import sort_by_tools, split_cols\n",
    "import pandas as pd\n",
    "import spot\n",
    "spot.setup()\n",
    "pd.options.display.max_colwidth = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of LTL to deterministic automata translators \n",
    "\n",
    "$\\newcommand{\\F}{\\mathsf{F}}\\newcommand{\\G}{\\mathsf{G}}\\newcommand{\\U}{\\mathsf{U}}\\newcommand{\\X}{\\mathsf{X}}$\n",
    "## Tools\n",
    "We have \n",
    "* tools that translate \\[fragments\\] of LTL into (generalized) Rabin automata:\n",
    " - [Rabinizer 3.1](https://www7.in.tum.de/~kretinsk/rabinizer3.html)\n",
    " - [Rabinizer 4](https://www7.in.tum.de/~kretinsk/rabinizer4.html)\n",
    " - [LTL3DRA](https://sourceforge.net/projects/ltl3dra/) v.0.2.6 \\[LTL$\\smallsetminus\\G$($\\U\\X$)\\]\n",
    "* tools that chain translation of LTL into cut-deterministic BÃ¼chi automata (aka LDBA) or into deterministic Rabin automata with a construction that create deterministic parity automaton. They avoid Safra-like determinization. Both are from the [owl/Rabinizer4 library](https://www7.in.tum.de/~kretinsk/rabinizer4.html)\n",
    " - ltl2dpa --mode=ldba\n",
    " - ltl2dpa --mode=rabinizer (relies on transition-based index appearance record)\n",
    "* tools that perform Safra-based determinization of N\\[G\\]BA into {Rabin/Parity} automata that use intermediete NBA\n",
    " - [ltl2dstar](http://ltl2dstar.de) \\[NBA only\\] {Rabin)}\n",
    " - autfilt from [Spot](https://spot.lrde.epita.fr/) 2.5 {parity}\n",
    " - here we use the following LTL2TGBA/LTL2NBA translators:\n",
    "   - ltl2tgba from [Spot](https://spot.lrde.epita.fr/) 2.5\n",
    "   - [LTL3BA](https://sourceforge.net/p/ltl3ba/) v. 1.1.3; we use LTL3BA in two settings:\n",
    "     - `ltl3ba` {LTL3BA}\n",
    "     - `ltl3ba -d` {LTL3BAd} which prefer more deterministic automata to smaller ones\n",
    " - we further use experimentaly for autfilt the LTL to Emerson-Lei automata translator\n",
    "   - [LTL3TELA](https://github.com/jurajmajor/ltl3tela) v.1.1.1\n",
    "* Safra's based determinization into deterministic parity automata that uses information about the LTL formula\n",
    " - `ltl2tgba -DG` from [Spot](https://spot.lrde.epita.fr/) 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 tools_hier.py > tools.tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners = {}\n",
    "cols=[\"states\",\"transitions\",\"acc\",\"time\",\"nondet_states\"]\n",
    "for source in ('literature','random'):\n",
    "    for t in ('full','ltl3dra'):\n",
    "        name = '{}_{}'.format(source,t)\n",
    "        tools = full_tools if t=='full' else ltl3dra_tools\n",
    "        runners[name] = \\\n",
    "            LtlcrossRunner(tools,\\\n",
    "                    res_filename='data/{}.csv'.format(name),\\\n",
    "                    formula_files=['formulae/{}.ltl'.format(name)],\\\n",
    "                    cols=cols)\n",
    "\n",
    "name = 'random_fg'\n",
    "tools = ltl3dra_tools\n",
    "runners[name] = LtlcrossRunner(tools,\\\n",
    "                    res_filename='data/{}.csv'.format(name),\\\n",
    "                    formula_files=['formulae/{}.ltl'.format(name)],\\\n",
    "                    cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, r in runners.items():\n",
    "    print('{}: Working on {}'.format(datetime.now().strftime('[%d.%m.%Y %T]'),name))\n",
    "    r.name = name\n",
    "    r.parse_results()\n",
    "    #r.compute_best()\n",
    "    r.na_incorrect()\n",
    "    r.orig_count = len(r.values)\n",
    "    r.clean_count = len(r.values.dropna())\n",
    "    r.compute_sbacc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, r in runners.items():\n",
    "    print('The benchmark {} started with {} formulae and has valid data for {} formulae'.format(name,r.orig_count,r.clean_count))\n",
    "    r.errors = {}\n",
    "    for e in ['timeout', 'parse error', 'incorrect', 'crash', 'no output']:\n",
    "        s = r.get_error_count(e).sum()\n",
    "        if not pd.isna(s):\n",
    "            r.errors[e] = r.get_error_count(e).sum()\n",
    "    s = pd.Series(r.errors, name='count')\n",
    "    s.index.name = 'error type'\n",
    "    display(s.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_runner(self,cols=['states','acc','time'],\n",
    "                   tool_subset=None, split_col_names=True, col_lev_names=None,\n",
    "                   counts = True):\n",
    "    '''Returns a dataframe with rows indexed by tools in\n",
    "    `tool_subset (or `self.tools.keys()`) and columns by\n",
    "    cols. The values are cummulative sums for respective\n",
    "    tool and column.'''\n",
    "    if tool_subset is None:\n",
    "        tool_subset = self.tools.keys()\n",
    "    name = self.name\n",
    "    name = name.replace('ltl3dra','ltl-gux')\n",
    "    if counts:\n",
    "        name = '{} ({})'.format(name,self.clean_count)\n",
    "    col_names = ['{}_{}'.format(name,c) for c in cols]\n",
    "    df = pd.DataFrame(columns=col_names,index=tool_subset)\n",
    "    for col in cols:\n",
    "        df['{}_{}'.format(name,col)] = self.cummulative(col).map(lambda x: '%0.0f' % x)\n",
    "    if split_col_names:\n",
    "        res = split_cols(df,axis=1,symbol='_',names=col_lev_names)\n",
    "    else:\n",
    "        res = df\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(compute_runner(r).head())\n",
    "display(compute_runner(r,split_col_names=False).head())\n",
    "compute_runner(r,col_lev_names=['source','fragment','metric']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "order = [\n",
    "    ('literature','full'),\n",
    "    ('literature','ltl3dra'),\n",
    "    ('random','full'),\n",
    "    ('random','ltl3dra'),\n",
    "    ('random','fg'),\n",
    "]\n",
    "for o in order:\n",
    "    data.append(compute_runner(runners['{}_{}'.format(o[0],o[1])]))\n",
    "res = pd.concat(data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_header_colors(lines):\n",
    "    lines = lines.replace('{c}','{b}',1)\n",
    "    i = lines.find('{c}')\n",
    "    return lines[:i+1] + lines[i+1:].replace('{c}','{b}',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_acc(acc,sb=False):\n",
    "    acc = acc.replace('TEL.TP','TEL.TEL')\n",
    "    if sb:\n",
    "        acc = re.sub(r'T([^T]+$)', r'S\\1', acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_tools(tool):\n",
    "    tool = tool.replace('ltl2dstar(NBA)',\n",
    "                        '\\parbox[c]{1.3cm}{\\centering ltl2dstar NBA}')\n",
    "    if tool == 'ltl2dstar':\n",
    "        tool = '\\parbox[c]{1.3cm}{\\centering ltl2dstar LTL}'\n",
    "    tool = tool.replace('Spot',\n",
    "                        #'\\rotatebox[origin=c]{90}{Spot (autfilt)}')\n",
    "                        '\\parbox[c]{1.3cm}{\\centering Spot autfilt}')\n",
    "    tool = tool.replace('R3','Rabinizer 3').replace('R4','Rabinizer 4')\n",
    "    tool = tool.replace('ltl2tgba','Spot')\n",
    "    return tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_frag(fr):\n",
    "    return '\\\\colorbox{{brown!30}}{{\\\\hspace{{.5cm}}{}\\\\hspace{{.5cm}}}}'.format(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_fragment(fr,vertical=False,color=None):\n",
    "    fr = fr.replace('full','full~~LTL')\n",
    "    fr = fr.replace('ltl-gux','\\LTLGUX')\n",
    "    fr = fr.replace('ltl3dra','\\LTLGUX')\n",
    "    fr = fr.replace('fg','\\FG').replace('(','[$').replace(')','$]')\n",
    "    if color:\n",
    "        source, fr = fr.split('_')\n",
    "        fr = '\\\\parbox[c]{{12.9ex}}{{\\centering {}}}'.format(fr)\n",
    "        if source == color:\n",
    "            fr = high_frag(fr)\n",
    "    if vertical:\n",
    "        fr = '\\rotatebox[origin=c]{90}{' + fr + '}'\n",
    "    return fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_index(df, columns=True, cross=False,\n",
    "                  inplace=False, vertical=False,\n",
    "                  sb=False, color=None):\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "    if cross:\n",
    "        i = [(fix_tools(t[0]),t[1],fix_acc(t[2],sb),t[3]) for t in df.index.values]\n",
    "    else:\n",
    "        i = [(fix_tools(t[0]),t[1],fix_acc(t[2],sb)) for t in df.index.values]\n",
    "    df.index=pd.MultiIndex.from_tuples(i)\n",
    "    if columns:\n",
    "        if cross:\n",
    "            vertical = vertical and len(df) > 4\n",
    "            ci = [(fix_fragment(t[0],vertical,color),t[1]) for t in df.columns.values]\n",
    "        else:\n",
    "            ci = [(t[0],fix_fragment(t[1]),t[2]) for t in df.columns.values]\n",
    "        df.columns=pd.MultiIndex.from_tuples(ci)\n",
    "    if not inplace:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_type_lines(filename,Safra=True,vertical=False,end=None):\n",
    "    cline = '\\cmidrule[\\lightrulewidth]{2-'+ str(end) +'}' \\\n",
    "        if vertical else '\\midrule'\n",
    "    todo = [(r'(\\\\multirow\\{2\\}\\{\\*\\}\\{ltl2dpa\\})',''),\n",
    "            (r'(\\\\multirow\\{3\\}\\{\\*\\}\\{\\\\parbox\\[c\\]\\{1.3cm\\}\\{\\\\centering ltl2dstar LTL\\}\\})','')]\n",
    "    if not Safra:\n",
    "        todo = [todo[0]]\n",
    "    if vertical:\n",
    "        todo = [(r\"&\\s+\"+t[0], ' & ') for t in todo]\n",
    "    for rplc, pref in todo:\n",
    "        with open(filename) as f:\n",
    "            lines = f.read()\n",
    "            lines = re.sub(rplc,cline + pref + r'\\1',lines)\n",
    "        with open(filename,\"w\") as f1:\n",
    "            f1.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lines(filename, end=12, vertical=False):\n",
    "    end = str(end)\n",
    "    todo = [(r\"(\\\\multirow\\{2\\}\\{\\*\\}\\{ltl2dpa\\})\",1,''),\n",
    "        (r\"(& \\\\multirow\\{2\\}\\{\\*\\}\\{Spot\\})\",2,'')]\n",
    "    if vertical:\n",
    "        todo = [(r\"&\\s+\"+t[0],t[1]+1, ' & ') for t in todo]\n",
    "    for rplc, start, pref in todo:\n",
    "        with open(filename) as f:\n",
    "            lines = f.read()\n",
    "        lines = re.sub(rplc,\n",
    "                       \"\\cmidrule{\" +\n",
    "                       \"{}-{}\".format(start,end) +\n",
    "                       \"}\" + pref + r\"\\1\",\n",
    "                       lines)\n",
    "        with open(filename,\"w\") as f1:\n",
    "            f1.write(lines)\n",
    "    with open(filename) as f:\n",
    "        lines = f.read()\n",
    "    lines = lines.replace('cline','cmidrule')\n",
    "    lines = lines.replace('$nan$','---')\n",
    "    if vertical:\n",
    "        rplc = \"\\cmidrule{1-\" + str(end) + \"}\"\n",
    "        lines = lines.replace(rplc,\"\\midrule[\\heavyrulewidth]\")\n",
    "    # Remove cmidrules in front of midrule\n",
    "    lines = re.sub(r\"(\\\\cmidrule\\{\\d+-\\d+\\}\\n?)*\\\\midrule\\[\\\\heavyrulewidth\\](\\s*\\n*\\s*\\\\cmidrule\\{\\d+-\\d+\\}\\s*\\n?)*\", \"\\\\midrule[\\\\heavyrulewidth] \", lines)\n",
    "    lines = re.sub(r\"(\\\\cmidrule\\{\\d+-\\d+\\}\\s*\\n?)*(\\\\cmidrule\\[\\\\lightrulewidth\\]\\{\\d+-\\d+\\})(\\s*\\n*\\s*\\\\cmidrule\\{\\d+-\\d+\\}\\s*\\n?)*\", r\"\\2 \", lines)\n",
    "    with open(filename,\"w\") as f1:\n",
    "        f1.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_table(filename, extrarowheight='.75ex'):\n",
    "    setup = '''\\\\newcolumntype{{a}}{{>{{\\\\columncolor{{blue!20}}}}r}}\n",
    "\\\\newcolumntype{{b}}{{>{{\\\\columncolor{{blue!20}}}}c}}\n",
    "\\\\setlength{{\\\\aboverulesep}}{{0pt}}\n",
    "\\\\setlength{{\\\\belowrulesep}}{{0pt}}\n",
    "\\\\setlength{{\\\\extrarowheight}}{{{}}}\n",
    "\\\\setlength{{\\\\heavyrulewidth}}{{2pt}}\n",
    "\\\\setlength{{\\\\lightrulewidth}}{{1.2pt}}\n",
    "\\\\def\\\\high{{\\\\cellcolor{{darkgreen!40}}}}\n",
    "'''.format(extrarowheight)\n",
    "    with open(filename) as f:\n",
    "        lines = f.read()\n",
    "    lines = fix_header_colors(lines)\n",
    "    with open(filename,\"w\") as f1:\n",
    "        f1.write(setup + lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heading(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.read()\n",
    "    lines = re.sub(r\"(\\s+)&\\s+&\\s+&\\s+states\", \n",
    "        r\"\\1main tool & intermediate & acc & states\",\n",
    "        lines)\n",
    "    lines = re.sub(r\"(\\s+)&\\s+&\\s+&\\s+&\\s+0\", \n",
    "        r\"\\1main tool & intermediate & acc & \\# & 0\",\n",
    "        lines)\n",
    "    with open(filename,\"w\") as f1:\n",
    "        f1.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_header_colors(lines):\n",
    "    lines = lines.replace('{c}','{b}',1)\n",
    "    i = lines.find('{c}')\n",
    "    return lines[:i+1] + lines[i+1:].replace('{c}','{b}',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cummulative_to_latex(res,file,transpose=False,color=True):\n",
    "    if transpose:\n",
    "        res = res.T\n",
    "    col_f = 'ccr'\n",
    "    color_type = 'a' if color else 'r'\n",
    "    for i in range(len(res.columns)//3):\n",
    "        if i % 2 == 0:\n",
    "            col_f += color_type*3\n",
    "        else:\n",
    "            col_f += 'rrr'\n",
    "    res = res\n",
    "    res.to_latex(buf=open(file,'w'), multirow=True,\n",
    "         escape=False, na_rep='---',\n",
    "         float_format=lambda x: '$' + '%0.0f' % x + '$',\n",
    "         column_format=col_f, multicolumn_format='c')\n",
    "    if color:\n",
    "        color_table(file,extrarowheight='.2ex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_min(data):\n",
    "    return ['\\high ${:0.0f}$'.format(m) if \n",
    "            m == data.min() else m for m in data]\n",
    "\n",
    "def high_max(data):\n",
    "    return ['\\high ${:0.0f}$'.format(m) if \n",
    "            m == data.max() else m for m in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sort_by_tools(res,tool_order)\n",
    "res = split_cols(res,axis=0,symbol='/')\n",
    "shorten_index(res,inplace=True)\n",
    "sorted_all = res.astype(float).apply(high_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative = [('random','rand'),('literature','lit')]\n",
    "for long, short in cumulative:\n",
    "    filename = 'cum_{}.tex'.format(short)\n",
    "    cummulative_to_latex(sorted_all[long], file=filename)\n",
    "    # We need to measure the # of columns in the LaTeX table\n",
    "    length = len(sorted_all[long].columns) +\\\n",
    "             len(sorted_all[long].index.levels)\n",
    "    fix_lines(filename,length)\n",
    "    add_type_lines(filename)\n",
    "    make_heading(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_str_multiindex_cols(df, color_type='a', def_type='r'):\n",
    "    col_f = '' # string to acummulate the columns' types\n",
    "    i = 0 # iterates over labels\n",
    "    c = 0 # remembers if this one should be colored\n",
    "    while i < len(df.columns):\n",
    "        col = df.columns.labels[0][i]\n",
    "        current_lab = df.columns.levels[0][col]\n",
    "        col_nums = len(df[current_lab].columns)\n",
    "        i += col_nums # moves to next column\n",
    "        if c % 2 == 0:\n",
    "            col_f += color_type*col_nums\n",
    "        else:\n",
    "            col_f += def_type*col_nums\n",
    "        if len(df[current_lab]) > 0:\n",
    "            c += 1\n",
    "    return col_f\n",
    "\n",
    "def multicol_single(df, col_type='c'):\n",
    "    df = df.copy()\n",
    "    def multicol(col):\n",
    "        return '\\\\multicolumn{{1}}{{{}}}{{{}}}'.format(col_type, col)\n",
    "    i = 0 # iterates over labels\n",
    "    create_multicol = []\n",
    "    while i < len(df.columns):\n",
    "        col = df.columns.labels[0][i]\n",
    "        current_lab = df.columns.levels[0][col]\n",
    "        col_nums = len(df[current_lab].columns)\n",
    "        if len(df[current_lab].columns) == 1:\n",
    "            create_multicol.append(current_lab)\n",
    "        i += col_nums # moves to next column\n",
    "    ci = [multicol(col) if col in create_multicol else col for \n",
    "          col in df.columns.levels[0]]\n",
    "    df.columns.set_levels(ci,level=0,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_to_latex(res,file,color=True):\n",
    "    col_f = 'l'\n",
    "    if color:\n",
    "        col_f += color_str_multiindex_cols(res,'a')\n",
    "    else:\n",
    "        col_f += 'r'*len(res.columns)\n",
    "    res = multicol_single(res)\n",
    "    res = res.dropna(how='all')\n",
    "    res.to_latex(buf=open(file,'w'), multirow=True,\n",
    "         escape=False, na_rep='---',\n",
    "         float_format=lambda x: '$' + '%0.0f' % x + '$',\n",
    "         column_format=col_f, multicolumn_format='c')\n",
    "    if color:\n",
    "        color_table(file)\n",
    "    fix_lines(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['literature_full',\n",
    " 'literature_ltl3dra',\n",
    " 'random_full',\n",
    " 'random_ltl3dra',\n",
    " 'random_fg']\n",
    "data = []\n",
    "for name in names:\n",
    "    r = runners[name]\n",
    "    errors = {}\n",
    "    for e in ['timeout', 'parse error', 'incorrect', 'crash', 'no output']:\n",
    "        s = pd.DataFrame(r.get_error_count(e))\n",
    "        if not s.empty:\n",
    "            errors[e] = s.unstack(level=0)\n",
    "    if len(errors) > 0:\n",
    "        res = pd.concat(errors,axis=1)\n",
    "        res.index = res.index.droplevel(0)\n",
    "        data.append(res)\n",
    "errors = pd.concat(data,keys=names,axis=1)\n",
    "ci = [(t[0].split('_')[0],\n",
    "       fix_fragment(t[0].split('_')[1]),\n",
    "       t[1].replace('parse error', '>32 marks')) for t in errors.columns.values]\n",
    "errors.columns = pd.MultiIndex.from_tuples(ci)\n",
    "errors.index = [tools_hier.fix_tool(t) for t in errors.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'errors_lit.tex'\n",
    "errors_to_latex(errors.literature,file)\n",
    "file = 'errors_rand.tex'\n",
    "errors_to_latex(errors.random,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tool `t1` wins against `t2` in the comparison also if `t2` fails and `t1` does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cross(df,victories=True):\n",
    "    df = split_cols(df,axis=0,symbol='/')  \n",
    "    df = df.T.reset_index(drop=True).T\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index(['level_0','level_1','level_2'],\n",
    "                      append=True)\n",
    "    df = df.reorder_levels([1,2,3,0])\n",
    "    df.index.names = ['','','','']\n",
    "    if victories:\n",
    "        cols = list(df.columns)\n",
    "        cols[len(cols)-1] = 'V'\n",
    "        df.columns = cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_to_latex(res, file='cross.tex', color=True,\n",
    "                   vertical=False):\n",
    "    col_f = 'cccrr' if vertical else 'ccrr'\n",
    "    color_type = 'a' if color else 'r'\n",
    "    for i in range(len(res.columns)):\n",
    "        if i % 2 == 0:\n",
    "            col_f += color_type\n",
    "        else:\n",
    "            col_f += 'r'\n",
    "    res = res\n",
    "    res.to_latex(buf=open(file,'w'), multirow=True,\n",
    "        escape=False,na_rep='---', \n",
    "        float_format=lambda x: '$' + '%0.0f' % x + '$',\n",
    "        column_format=col_f,multicolumn_format='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cross(runners_base, tools, \n",
    "                 fragments=['full','ltl3dra'],\n",
    "                 cols=['states','acc'],\n",
    "                 vertical=False, merge_in_latex=True,\n",
    "                 filename='cross.tex', latex=True,\n",
    "                 counts=True):   \n",
    "    def to_latex(table, filename=filename, vertical=False):\n",
    "        table = table.copy()\n",
    "        if vertical:\n",
    "            data = []\n",
    "            for k in table.index.levels[0]:\n",
    "                data.append(\n",
    "                    pd.DataFrame(table.loc[k,'V']).\\\n",
    "                    apply(high_max))\n",
    "                vict = pd.concat(data,\n",
    "                    keys=table.index.levels[0])\n",
    "            table.loc[:,'V'] = vict\n",
    "        else:\n",
    "            table.loc(axis=1)[:,'V'] = \\\n",
    "                table.loc(axis=1)[:,'V'].apply(high_max)\n",
    "        cross_to_latex(table, file=filename, \n",
    "                       vertical=vertical)\n",
    "        end = len(table.columns) + len(table.index.levels)\n",
    "        add_type_lines(filename, Safra=False, \n",
    "                       vertical=vertical, end=end)\n",
    "        fix_lines(filename, end, vertical)\n",
    "        color_table(filename)\n",
    "        make_heading(filename)\n",
    "    \n",
    "    state_based = 'sb_states' in cols\n",
    "    data = []\n",
    "    fr_and_c = []\n",
    "    for fr in fragments:\n",
    "        r = runners['{}_{}'.format(runners_base,fr)]\n",
    "        fr_and_c.append('{} ({})'.format(fr,r.orig_count))\n",
    "        res = r.cross_compare(tools=tools,props=cols)\n",
    "        cross = prepare_cross(res)\n",
    "        data.append(cross)\n",
    "        if latex and not merge_in_latex:\n",
    "            table = pd.concat([cross], axis=1, keys=[fr])\n",
    "            table = shorten_index(table,cross=True,\n",
    "                        columns=False,inplace=False,\n",
    "                        sb=state_based)\n",
    "            fr_name = '{}_{}.tex'.format(filename[:-4],fr)\n",
    "            to_latex(table, fr_name)\n",
    "    if counts:\n",
    "        fragments = fr_and_c\n",
    "    table = pd.concat(data, axis=1, keys=fragments)\n",
    "    shorten_index(table, cross=True, inplace=True,\n",
    "                  vertical=vertical,\n",
    "                  sb=state_based)\n",
    "    if vertical:\n",
    "        fragments = [fix_fragment(f, vertical = \n",
    "                     len(table) > 4)\n",
    "                     for f in fragments]\n",
    "        data = [table[f] for f in fragments]\n",
    "        table = pd.concat(data,keys=fragments)\n",
    "    if latex and merge_in_latex:\n",
    "        to_latex(table,filename,vertical)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cross_merged(tools, \n",
    "                 cols=['states','acc'],\n",
    "                 vertical=False, merge_in_latex=True,\n",
    "                 filename='cross_merged.tex', latex=True,\n",
    "                 counts=True, color='random'):\n",
    "    def to_latex(table, filename=filename, vertical=False):\n",
    "        table = table.copy()\n",
    "        if vertical:\n",
    "            data = []\n",
    "            for k in table.index.levels[0]:\n",
    "                data.append(\n",
    "                    pd.DataFrame(table.loc[k,'V']).\\\n",
    "                    apply(high_max))\n",
    "                vict = pd.concat(data,\n",
    "                    keys=table.index.levels[0])\n",
    "            table.loc[:,'V'] = vict\n",
    "        else:\n",
    "            table.loc(axis=1)[:,'V'] = \\\n",
    "                table.loc(axis=1)[:,'V'].apply(high_max)\n",
    "        cross_to_latex(table, file=filename, \n",
    "                       vertical=vertical)\n",
    "        end = len(table.columns) + len(table.index.levels)\n",
    "        add_type_lines(filename, Safra=False, \n",
    "                       vertical=vertical, end=end)\n",
    "        fix_lines(filename, end, vertical)\n",
    "        color_table(filename)\n",
    "        make_heading(filename)\n",
    "    \n",
    "    state_based = 'sb_states' in cols\n",
    "    data = []\n",
    "    fr_and_c = []\n",
    "    r_order = ['literature_full','literature_ltl3dra',\n",
    "               'random_full','random_ltl3dra','random_fg']\n",
    "    for name in r_order:\n",
    "        r = runners[name]\n",
    "        source, fr = name.split('_')\n",
    "        fr_and_c.append('{} ({})'.format(name,r.orig_count))\n",
    "        res = r.cross_compare(tools=tools,props=cols)\n",
    "        cross = prepare_cross(res)\n",
    "        data.append(cross)\n",
    "    if counts:\n",
    "        fragments = fr_and_c\n",
    "    table = pd.concat(data, axis=1, keys=fragments)\n",
    "    shorten_index(table, cross=True, inplace=True,\n",
    "                  vertical=vertical,\n",
    "                  sb=state_based,\n",
    "                  color=color)\n",
    "    if vertical:\n",
    "        fragments = [fix_fragment(f, vertical = \n",
    "                     len(table) > 4, color=color)\n",
    "                     for f in fragments]\n",
    "        data = [table[f] for f in fragments]\n",
    "        table = pd.concat(data,keys=fragments)\n",
    "    if latex and merge_in_latex:\n",
    "        to_latex(table,filename,vertical)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = [t for t in tool_order if\n",
    "          'LTL3DRA' in t or\n",
    "          'R3' in t or 'R4' in t]\n",
    "tgr = [t for t in tool_order if\n",
    "       'TGR' in t]\n",
    "ltl2dstar = [t for t in tool_order if 'ltl2dstar' in t]\n",
    "spot = [t for t in tool_order if \n",
    "        t.startswith('Spot') or\n",
    "        'ltl2tgba' in t]\n",
    "ltl2dpa = ['ltl2dpa/ldba/TP','ltl2dpa/Rab/TP']\n",
    "Safra = ltl2dstar + spot\n",
    "selection = [t for t in tool_order if\n",
    "             'R4//TGR' in t or\n",
    "             'ltl2dpa' in t or\n",
    "             #'ltl2dstar/Spot' in t or\n",
    "             'ltl2tgba' in t\n",
    "]\n",
    "toolsets = {\n",
    "    'direct' : direct,\n",
    "    'ltl2dstar' : ltl2dstar,\n",
    "    'spot' : spot,\n",
    "    'selection' : selection\n",
    "    #'parity' : parity,\n",
    "    #'best' : best\n",
    "}\n",
    "toolsets_sbacc = {\n",
    "    #'Safra_sel' : Safra_sel,\n",
    "    #'Rabin' : Rabin,\n",
    "    #'selection_sr' : selection_sr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, tools in toolsets.items():\n",
    "    filename = 'cross_m_{}.tex'.format(name)\n",
    "    create_cross_merged(tools, \n",
    "                 filename=filename, merge_in_latex=True,\n",
    "                 vertical=True)\n",
    "for name, tools in toolsets_sbacc.items():\n",
    "    filename = 'cross_m_{}.tex'.format(name)\n",
    "    create_cross_merged(tools, cols=['sb_states','acc'],\n",
    "                 filename=filename, merge_in_latex=True,\n",
    "                 vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar plots for minimal automata counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approaches = {\n",
    "    'direct' : direct,\n",
    "    'Safra'  : Safra,\n",
    "    'ltl2dpa': ltl2dpa    \n",
    "}\n",
    "app_order = ['direct','Safra','ltl2dpa']\n",
    "fr_order = ['full','ltl3dra','fg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in runners.values():\n",
    "    for ap_name, tools in approaches.items():\n",
    "        r.compute_best(tools, ap_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_data(runners, tools, restrict_tools=False, unique_only=False,col='states'):\n",
    "    '''\n",
    "    runners : list of runners\n",
    "    tools : list of tools in their order\n",
    "    '''\n",
    "    data = {}\n",
    "    if isinstance(runners,dict):\n",
    "        runners = runners.values()\n",
    "    for r in runners:\n",
    "        res = r.min_counts(tools, restrict_tools=restrict_tools,\n",
    "                           unique_only=unique_only,col=col)\n",
    "        if unique_only:\n",
    "            nu = pd.DataFrame(index=['nonunique'],columns=[0])\n",
    "            nu[0]=[r.orig_count-res.sum()[0]]\n",
    "            res = res.append(nu)\n",
    "        ## sets tool from index to a columns\n",
    "        res.index.name = 'tool'\n",
    "        res.reset_index(inplace=True)\n",
    "        r.orig_c_name = '{} [{}]'.format(r.name, r.orig_count)\n",
    "        data[r.orig_c_name] = res\n",
    "    ret = pd.concat(data, names = ['benchmark'])\n",
    "    ret = ret.reset_index(drop=True,level=1)\n",
    "    df = split_cols(ret,'_',axis=0,names=['source','fragment'])\n",
    "    df = df.reset_index().set_index(['source','fragment','tool'])\n",
    "    df.index = df.index.droplevel(0)\n",
    "    df = df.unstack().swaplevel(axis=1)\n",
    "    df.columns = df.columns.droplevel(1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_plot(d, tools, alternate_labels=False):\n",
    "    frags = []\n",
    "    for f in fr_order:\n",
    "        for rf in d[tools[0]].keys():\n",
    "            if rf.startswith(f):\n",
    "                frags.append(rf)\n",
    "    alt_str = 'nodes near coords align={below=10pt, anchor=north}'\n",
    "    res = ''\n",
    "    i = 0\n",
    "    for tool in tools:\n",
    "        vals = d[tool]\n",
    "        coords = ['({},{})'.format(vals[fr],fr) if not math.isnan(vals[fr]) else \n",
    "                  '(0,{})'.format(fr) for fr in frags]\n",
    "        if not alternate_labels or i % 2 == 0:\n",
    "            res += '\\\\addplot coordinates {{{}}};\\n'.format(' '.join(coords))\n",
    "        else:\n",
    "            res += '\\\\addplot+[{}] coordinates {{{}}};\\n'.format(alt_str,' '.join(coords))\n",
    "        res += '\\\\addlegendentry{{{}}}\\n'.format(tool)\n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_bar_plot(df,tools,filename=None,kw=None):\n",
    "    d = df.to_dict()\n",
    "    fr = []\n",
    "    for f in fr_order:\n",
    "        for rf in d[tools[0]].keys():\n",
    "            if rf.startswith(f):\n",
    "                fr.append(rf)\n",
    "    fr.reverse()\n",
    "\n",
    "    #Process kw args\n",
    "    if kw is not None:\n",
    "        args = ['{}={},\\n'.format(k,v) for k,v in kw.items()]\n",
    "        args = ''.join(args)\n",
    "    else:\n",
    "        args = ''\n",
    "\n",
    "    coords = dict_to_plot(d,tools)\n",
    "    res = '''\\\\begin{{tikzpicture}}[scale=.83]\n",
    "\\\\pgfplotsset{{compat=1.14}}\n",
    "\\\\pgfplotsset{{every axis legend/.append style=\n",
    "{{nodes={{text width=2cm, inner xsep=5pt,text depth=0.15em}}}}}}\n",
    "\\\\begin{{axis}}[\n",
    "xbar=-22pt, xmin=0,\n",
    "axis x line* = bottom,\n",
    "axis y line* = left,\n",
    "width=12cm, height={}cm, enlarge y limits={},\n",
    "xlabel={{\\\\# of automata with minimal size}},\n",
    "symbolic y coords={{{}}},\n",
    "ytick={{{}}},\n",
    "yticklabels={{{}}},\n",
    "yticklabel style={{align=center, text width=1.95cm}},\n",
    "nodes near coords, nodes near coords align={{horizontal}},\n",
    "legend style={{at={{(0.5,1.05)}},\n",
    "    anchor=south,legend columns=-1,\n",
    "    }},\n",
    "{}%\n",
    "]\n",
    "{}%\n",
    "\\\\end{{axis}}\n",
    "\\\\end{{tikzpicture}}'''.format(2.5*len(fr),\n",
    "                               1/len(fr),\n",
    "                               ','.join(fr),\n",
    "                               ','.join(fr),\n",
    "                               ','.join([fix_fragment(f) for f in fr]),\n",
    "                               args,\n",
    "                               coords)\n",
    "    if filename is not None:\n",
    "        print(res,file=open(filename,'w'))\n",
    "    else: \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_stacked_bar_plot(df,tools,filename=None,alternate=False,kw=None):\n",
    "    d = df.to_dict()\n",
    "    fr = []\n",
    "    for f in fr_order:\n",
    "        for rf in d[tools[0]].keys():\n",
    "            if rf.startswith(f):\n",
    "                fr.append(rf)\n",
    "    fr.reverse()\n",
    "\n",
    "    #Process kw args\n",
    "    if kw is not None:\n",
    "        args = ['{}={},\\n'.format(k,v) for k,v in kw.items()]\n",
    "        args = ''.join(args)\n",
    "    else:\n",
    "        args = ''\n",
    "\n",
    "    coords = dict_to_plot(df.to_dict(),tools, alternate)\n",
    "    res = '''\\\\begin{{tikzpicture}}[scale=.81]\n",
    "\\\\pgfplotsset{{compat=1.14}}\n",
    "\\pgfplotsset{{every axis legend/.append style=\n",
    "{{nodes={{text width=1.6cm, inner xsep=5pt,text depth=0.15em}}}}}}\n",
    "\\\\begin{{axis}}[\n",
    "xbar stacked, xmin=0,\n",
    "bar width=20pt,\n",
    "axis x line* = bottom,\n",
    "axis y line* = left,\n",
    "width=12cm, height={}cm, enlarge y limits={},\n",
    "xlabel={{\\\\# of automata with minimal size}},\n",
    "symbolic y coords={{{}}},\n",
    "ytick={{{}}},\n",
    "yticklabels={{{}}},\n",
    "yticklabel style={{align=center, text width=1.95cm}},\n",
    "nodes near coords, nodes near coords align={{above=10pt, anchor=south}},\n",
    "legend style={{at={{(0.5,1.05)}},\n",
    "    anchor=south,legend columns=-1}},\n",
    "{}%\n",
    "]\n",
    "{}%\n",
    "\\\\end{{axis}}\n",
    "\\\\end{{tikzpicture}}'''.format(2*len(fr)+1.5,\n",
    "                               1/len(fr),\n",
    "                               ','.join(fr),\n",
    "                               ','.join(fr),\n",
    "                               ','.join([fix_fragment(f) for f in fr]),\n",
    "                               args,\n",
    "                               coords)\n",
    "    if filename is not None:\n",
    "        print(res,file=open(filename,'w'))\n",
    "    else: \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_bar(runners, tools, filename=None,kw=None):\n",
    "    return min_bar_plot(get_min_data(runners,tools),\n",
    "                        tools,filename,kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_stacked(runners, tools, filename=None, alternate=False,kw=None):\n",
    "    df =  get_min_data(runners,tools,restrict_tools=True,unique_only=True)\n",
    "    return min_stacked_bar_plot(df, tools+['nonunique'], \n",
    "                                filename, alternate,kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit = [r for r in runners.values() if 'lit' in r.name]\n",
    "rand = [r for r in runners.values() if 'random' in r.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second = {'legend to name' : 'nope'}\n",
    "min_bar(lit,app_order,'min_bar_lit.tex')\n",
    "min_bar(rand,app_order,'min_bar_rand.tex',kw=second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_stacked(lit,app_order,'min_st_bar_lit.tex')\n",
    "min_stacked(rand,app_order,'min_st_bar_rand.tex',True,kw=second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_data(runners.values(),['ltl2tgba//TP','Spot/LTL3TELA/TEL.TP'],unique_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse plot for tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_plot_inv(d, tools, alternate_labels=False):\n",
    "    frags = []\n",
    "    for f in fr_order:\n",
    "        for rf in d:\n",
    "            if rf.startswith(f):\n",
    "                frags.append(rf)\n",
    "    to = [t for t in tool_order if t in tools]\n",
    "    alt_str = 'nodes near coords align={below=10pt, anchor=north}'\n",
    "    res = ''\n",
    "    i = 0\n",
    "    for f in frags:\n",
    "        vals = d[f]\n",
    "        coords = ['({},{{{}}})'.format(vals[tool],tool) if not math.isnan(vals[tool]) else \n",
    "                  '(0,{{{}}})'.format(tool) for tool in to]\n",
    "        if not alternate_labels or i % 2 == 0:\n",
    "            res += '\\\\addplot coordinates {{{}}};\\n'.format(' '.join(coords))\n",
    "        else:\n",
    "            res += '\\\\addplot+[{}] coordinates {{{}}};\\n'.format(alt_str,' '.join(coords))\n",
    "        res += '\\\\addlegendentry{{{}}}\\n'.format(fix_fragment(f))\n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_bar_plot_inv(df,tools,filename=None,kw=None):\n",
    "    d = df.to_dict()\n",
    "    fr = []\n",
    "    for f in fr_order:\n",
    "        for rf in d:\n",
    "            if rf.startswith(f):\n",
    "                fr.append(rf)\n",
    "    fr.reverse()\n",
    "    tools = tools.copy()\n",
    "    tools.reverse()\n",
    "    coords = dict_to_plot_inv(d,tools)\n",
    "    if kw is not None:\n",
    "        args = ['{}={},\\n'.format(k,v) for k,v in kw.items()]\n",
    "        args = ''.join(args)\n",
    "    else:\n",
    "        args = ''\n",
    "    res = '''\\\\begin{{tikzpicture}}\n",
    "\\\\pgfplotsset{{compat=1.14}}\n",
    "\\\\pgfplotsset{{every axis legend/.append style=\n",
    "{{nodes={{inner xsep=5pt,\n",
    "text depth=,align=center}}}}}}\n",
    "\\\\begin{{axis}}[\n",
    "xbar=-12pt, xmin=0,\n",
    "bar width=5pt,\n",
    "axis x line* = bottom,\n",
    "axis y line* = left,\n",
    "width=6.8cm, height={}cm, enlarge y limits={},\n",
    "xlabel={{\\\\# of automata with minimal size}},\n",
    "symbolic y coords={{{}}},\n",
    "ytick={{{}}},\n",
    "yticklabels={{{}}},\n",
    "yticklabel style={{align=left,font=\\\\small}},\n",
    "nodes near coords, nodes near coords align={{horizontal}},\n",
    "nodes near coords style={{font=\\\\small}},\n",
    "legend style={{at={{(0.5,1.05)}},\n",
    "    anchor=south,legend columns=-1,\n",
    "    }},\n",
    "{}%\n",
    "]\n",
    "{}%\n",
    "\\\\end{{axis}}\n",
    "\\\\end{{tikzpicture}}'''.format(len(tools),\n",
    "                               1/len(tools),\n",
    "                               ','.join(tools),\n",
    "                               ','.join(tools),\n",
    "                               ','.join([tools_hier.fix_tool(t) for t in tools]),\n",
    "                               args,\n",
    "                               coords)\n",
    "    if filename is not None:\n",
    "        print(res,file=open(filename,'w'),end='%')\n",
    "    else: \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_bar_inv(runners, tools, filename=None,col='states',kw=None):\n",
    "    return min_bar_plot_inv(get_min_data(runners,tools,col=col).T,tools,filename,kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_l = {'legend to name' : 'leg_min_l'}\n",
    "first_r = {'legend to name' : 'leg_min_r'}\n",
    "marks = {'title' : 'mixed marks'}\n",
    "first_l.update(marks)\n",
    "first_r.update(marks)\n",
    "second = {'yticklabels' : '', 'legend to name' : 'xxx', 'title': 'marks on states'}\n",
    "min_bar_inv(lit,tool_order,'min_bar_lit_inv.tex',kw=first_l)\n",
    "min_bar_inv(lit,tool_order,'min_bar_lit_sbacc_inv.tex',col='sb_states', kw=second)\n",
    "min_bar_inv(rand,tool_order,'min_bar_rand_inv.tex',kw=first_r)\n",
    "min_bar_inv(rand,tool_order,'min_bar_rand_sbacc_inv.tex',col='sb_states', kw=second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorted plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_plot(self,tools,filename=None,col='states',short=False):\n",
    "    tool_coord = '''\\\\addplot coordinates {{{}}};%\n",
    "\\\\addlegendentry{{{}}}%\n",
    "'''\n",
    "    sh_width = '11cm'\n",
    "    width = sh_width if short else '16cm'\n",
    "    v = r.values[col].loc(axis=1)[tools].dropna()\n",
    "    coords_str = ''\n",
    "    for tool in tools:\n",
    "        values = sorted(list(v[tool]))\n",
    "        t_coords = ['({},{})'.format(i,values[i]) for i in range(len(values))]\n",
    "        t_coords_str = ' '.join(t_coords)\n",
    "        coords_str += tool_coord.format(t_coords_str,tools_hier.fix_tool(tool))\n",
    "    res = '''\\\\begin{{tikzpicture}}\n",
    "\\\\pgfplotsset{{every axis legend/.append style={{\n",
    "cells={{anchor=west}},\n",
    "draw=none,\n",
    "}}}}\n",
    "\\\\pgfplotsset{{compat=1.14}}\n",
    "\\\\begin{{semilogyaxis}}[\n",
    "xmin=0,xmax={},\n",
    "thick,\n",
    "no markers,\n",
    "cycle list name=linestyles*,\n",
    "axis x line* = bottom,\n",
    "axis y line* = left,\n",
    "width={}, height=7cm, \n",
    "xlabel={{$n$-th smallest automaton}},\n",
    "ylabel={{states}},\n",
    "legend pos = north west,\n",
    "cycle list={{%\n",
    "{{darkgreen, solid}},\n",
    "{{blue, densely dashed}},\n",
    "{{red, dashdotdotted}},\n",
    "{{black, densely dotted}},\n",
    "{{brown, loosely dashdotted}}\n",
    "}}\n",
    "]\n",
    "{}\n",
    "\\\\end{{semilogyaxis}}\n",
    "\\\\end{{tikzpicture}}'''.format(len(self.values),\n",
    "                               width,\n",
    "                               coords_str)\n",
    "    if filename is not None:\n",
    "        print(res,file=open(filename,'w'))\n",
    "    else: \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ['Spot/LTL3TELA/TEL.TP','Spot/LTL3BA/TGB.TP','ltl2tgba//TP']\n",
    "min_name = 'min(Spot)'\n",
    "for name in ['random_fg','random_ltl3dra']:\n",
    "    r = runners[name]\n",
    "    r.compute_best(spot,min_name)\n",
    "    sorted_plot(r,[min_name]+t,'quantile_ltl3tela_{}.tex'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plots for non-equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_plot(r,t1,t2,filename=None,include_equal = True,col='states',log=None,size=(7,6.5),kw=None,clip=None, add_count=True):\n",
    "    merged = isinstance(r,list)\n",
    "    if merged:\n",
    "        vals = pd.concat([run.values[col] for run in r])\n",
    "        vals.index = vals.index.droplevel(0)\n",
    "        vals = vals.groupby(vals.index).first()\n",
    "    else:\n",
    "        vals = r.values[col]\n",
    "    to_plot = vals.loc(axis=1)[[t1,t2]] if include_equal else\\\n",
    "        vals[vals[t1] != vals[t2]].loc(axis=1)[[t1,t2]]\n",
    "    to_plot['count'] = 1\n",
    "    to_plot.dropna(inplace=True)\n",
    "    to_plot = to_plot.groupby([t1,t2]).count().reset_index()\n",
    "    if filename is not None:\n",
    "        print(scatter_plot(to_plot, log=log, size=size,kw=kw,clip=clip, add_count=add_count),file=open(filename,'w'))\n",
    "    else:\n",
    "        return scatter_plot(to_plot, log=log, size=size,kw=kw,clip=clip, add_count=add_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(df, short_toolnames=True, log=None, size=(7,6.5),kw=None,clip=None,add_count = True):\n",
    "    t1, t2, _ = df.columns.values\n",
    "    if short_toolnames:\n",
    "        t1 = fix_tools(t1.split('/')[0])\n",
    "        t2 = fix_tools(t2.split('/')[0])\n",
    "    vals = ['({},{}) [{}]\\n'.format(v1,v2,c) for v1,v2,c in df.values]\n",
    "    plots = '''\\\\addplot[\n",
    "    scatter, scatter src=explicit, \n",
    "    only marks, fill opacity=0.5,\n",
    "    draw opacity=0] coordinates\n",
    "    {{{}}};'''.format(' '.join(vals))\n",
    "    start_line = 0 if log is None else 1\n",
    "    line = '\\\\addplot[darkgreen,domain={}:{}]{{x}};'.format(start_line, min(df.max(axis=0)[:2])+1)\n",
    "    axis = 'axis'\n",
    "    mins = 'xmin=0,ymin=0,'\n",
    "    clip_str = ''\n",
    "    if clip is not None:\n",
    "        clip_str = '\\\\draw[red,thick] ({},{}) rectangle ({},{});'.format(*clip)\n",
    "    if log:\n",
    "        if log == 'both':\n",
    "            axis = 'loglogaxis'\n",
    "            mins = 'xmin=1,ymin=1,'\n",
    "        else:\n",
    "            axis = 'semilog{}axis'.format(log)\n",
    "            mins = mins + '{}min=1,'.format(log)\n",
    "    args = ''\n",
    "    if kw is not None:\n",
    "        if 'title' in kw and add_count:\n",
    "            kw['title'] = '{{{} [{}]}}'.format(kw['title'],df['count'].sum())\n",
    "        args = ['{}={},\\n'.format(k,v) for k,v in kw.items()]\n",
    "        args = ''.join(args)\n",
    "    res = '''%\\\\begin{{tikzpicture}}\n",
    "\\\\pgfplotsset{{every axis legend/.append style={{\n",
    "cells={{anchor=west}},\n",
    "draw=none,\n",
    "}}}}\n",
    "\\\\pgfplotsset{{colorbar/width=.3cm}}\n",
    "\\\\pgfplotsset{{title style={{align=center,\n",
    "                        font=\\\\small}}}}\n",
    "\\\\pgfplotsset{{compat=1.14}}\n",
    "\\\\begin{{{0}}}[\n",
    "{1}\n",
    "colorbar,\n",
    "%thick,\n",
    "axis x line* = bottom,\n",
    "axis y line* = left,\n",
    "width={2}cm, height={3}cm, \n",
    "xlabel={{{4}}},\n",
    "ylabel={{{5}}},\n",
    "cycle list={{%\n",
    "{{darkgreen, solid}},\n",
    "{{blue, densely dashed}},\n",
    "{{red, dashdotdotted}},\n",
    "{{brown, densely dotted}},\n",
    "{{black, loosely dashdotted}}\n",
    "}},\n",
    "{6}%\n",
    "]\n",
    "{7}%\n",
    "{8}%\n",
    "{9}%\n",
    "\\\\end{{{0}}}\n",
    "%\\\\end{{tikzpicture}}\n",
    "'''.format(axis,mins,\n",
    "                    size[0],size[1],t1,t2,\n",
    "                    args,plots,line,\n",
    "                    clip_str)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltl2tgba = 'ltl2tgba//TP'\n",
    "ltl2dstar = 'ltl2dstar/Spot/SB.SR'\n",
    "margin_size = (4.3,6)\n",
    "clip_names = ('xmin','ymin','xmax','ymax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (4.75,6)\n",
    "clips = {\n",
    "    'full' : (0,0,33,33),\n",
    "    'ltl3dra' : (0,0,22,22),\n",
    "}\n",
    "fr_runs = {\n",
    "    'full' : [r for name, r in runners.items() if 'full' in name],\n",
    "    'ltl3dra' : [r for name, r in runners.items() if 'ltl3dra' in name],\n",
    "    'fg' : runners['random_fg']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, r in fr_runs.items():\n",
    "    fr = fix_fragment(name)\n",
    "    clip = None\n",
    "    kw={'title' : fr}\n",
    "    # reuse the y axis labels from previous\n",
    "    if name in ['ltl3dra','fg']:\n",
    "        kw['ylabel'] = ''\n",
    "    if name in clips:\n",
    "        clip = clips[name]\n",
    "        cl_kw = kw.copy()\n",
    "        cl_kw['title'] = '\\\\\\\\zoom'\n",
    "        cl_kw.update(zip(clip_names,clip))\n",
    "    saf_kw = kw.copy()\n",
    "    # reuse the y axis labels from zooms\n",
    "    # and make the one without zoom overlayed\n",
    "    #if name in ['ltl3dra','full']:\n",
    "    #    kw['xlabel'] = ''\n",
    "    #else:\n",
    "    #    kw['xlabel style'] = '{overlay}'\n",
    "    sc_plot(r,'R4//TGR',ltl2tgba,'sc_best_{}.tex'.format(name),size=size,kw=kw,clip=clip)\n",
    "    if clip is not None:\n",
    "        sc_plot(r,'R4//TGR',ltl2tgba,'sc_best_clip_{}.tex'.format(name),size=size,kw=cl_kw,add_count=False)\n",
    "    \n",
    "    ### Safra: plots for ltl2dstar and Spot\n",
    "    saf_kw['title'] = 'marks on states\\\\\\\\' + saf_kw['title']\n",
    "    if 'ylabel' not in saf_kw:\n",
    "        saf_kw['ylabel'] = 'ltl2dstar (LTL)'\n",
    "    sc_plot(r,ltl2tgba,ltl2dstar,'sc_Saf_{}.tex'.format(name),\n",
    "            col='sb_states',log='both',size=size,\n",
    "            kw=saf_kw)\n",
    "\n",
    "size = (4.6,6)\n",
    "ltl3tela_kw = {'ylabel' : 'Spot + LTL3TELA'}\n",
    "ltl3tela_clip = (0,0,5,20)\n",
    "sc_plot(runners['random_fg'],'R4//TGR',\n",
    "        'Spot/LTL3TELA/TEL.TP','sc_ltl3tela.tex',\n",
    "        size=size,clip=ltl3tela_clip,kw=ltl3tela_kw)\n",
    "ltl3tela_kw.update(zip(clip_names,ltl3tela_clip))\n",
    "ltl3tela_kw['ylabel'] = ''\n",
    "ltl3tela_kw['title'] = 'zoom'\n",
    "sc_plot(runners['random_fg'],'R4//TGR',\n",
    "        'Spot/LTL3TELA/TEL.TP','sc_clip_ltl3tela.tex',\n",
    "        size=size,kw=ltl3tela_kw,add_count=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
