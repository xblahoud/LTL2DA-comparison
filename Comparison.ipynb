{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from ltlcross_runner import LtlcrossRunner\n",
    "from tools_hier import get_tools, ltl3dra_tools, full_tools, tool_order\n",
    "from evaluation_utils import sort_by_tools, split_cols\n",
    "import pandas as pd\n",
    "import spot\n",
    "spot.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of LTL to deterministic automata translators \n",
    "\n",
    "$\\newcommand{\\F}{\\mathsf{F}}\\newcommand{\\G}{\\mathsf{G}}\\newcommand{\\U}{\\mathsf{U}}\\newcommand{\\X}{\\mathsf{X}}$\n",
    "## Tools\n",
    "We have \n",
    "* tools that translate \\[fragments\\] of LTL into (generalized) Rabin automata:\n",
    " - [Rabinizer 3.1](https://www7.in.tum.de/~kretinsk/rabinizer3.html)\n",
    " - [Rabinizer 4](https://www7.in.tum.de/~kretinsk/rabinizer4.html)\n",
    " - [LTL3DRA](https://sourceforge.net/projects/ltl3dra/) v.0.2.6 \\[LTL$\\smallsetminus\\G$($\\U\\X$)\\]\n",
    "* tools that chain translation of LTL into cut-deterministic BÃ¼chi automata (aka LDBA) or into deterministic Rabin automata with a construction that create deterministic parity automaton. They avoid Safra-like determinization. Both are from the [owl/Rabinizer4 library](https://www7.in.tum.de/~kretinsk/rabinizer4.html)\n",
    " - ltl2dpa --mode=ldba\n",
    " - ltl2dpa --mode=rabinizer (relies on transition-based index appearance record)\n",
    "* tools that perform Safra-based determinization of N\\[G\\]BA into {Rabin/Parity} automata that use intermediete NBA\n",
    " - [ltl2dstar](http://ltl2dstar.de) \\[NBA only\\] {Rabin)}\n",
    " - autfilt from [Spot](https://spot.lrde.epita.fr/) 2.5 {parity}\n",
    " - here we use the following LTL2TGBA/LTL2NBA translators:\n",
    "   - ltl2tgba from [Spot](https://spot.lrde.epita.fr/) 2.5\n",
    "   - [LTL3BA](https://sourceforge.net/p/ltl3ba/) v. 1.1.3; we use LTL3BA in two settings:\n",
    "     - `ltl3ba` {LTL3BA}\n",
    "     - `ltl3ba -d` {LTL3BAd} which prefer more deterministic automata to smaller ones\n",
    " - we further use experimentaly for autfilt the LTL to Emerson-Lei automata translator\n",
    "   - [LTL3TELA](https://github.com/jurajmajor/ltl3tela) v.1.1.1\n",
    "* Safra's based determinization into deterministic parity automata that uses information about the LTL formula\n",
    " - `ltl2tgba -DG` from [Spot](https://spot.lrde.epita.fr/) 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners = {}\n",
    "cols=[\"states\",\"transitions\",\"acc\",\"time\",\"nondet_states\"]\n",
    "for source in ('literature','random'):\n",
    "    for t in ('full','ltl3dra'):\n",
    "        name = '{}_{}'.format(source,t)\n",
    "        tools = full_tools if t=='full' else ltl3dra_tools\n",
    "        runners[name] = \\\n",
    "            LtlcrossRunner(tools,\\\n",
    "                    res_filename='data/{}.csv'.format(name),\\\n",
    "                    formula_files=['formulae/{}.ltl'.format(name)],\\\n",
    "                    cols=cols)\n",
    "\n",
    "name = 'random_fg'\n",
    "tools = ltl3dra_tools\n",
    "runners[name] = LtlcrossRunner(tools,\\\n",
    "                    res_filename='data/{}.csv'.format(name),\\\n",
    "                    formula_files=['formulae/{}.ltl'.format(name)],\\\n",
    "                    cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, r in runners.items():\n",
    "    print('{}: Working on {}'.format(datetime.now().strftime('[%d.%m.%Y %T]'),name))\n",
    "    r.name = name\n",
    "    r.parse_results()\n",
    "    r.na_incorrect()\n",
    "    r.orig_count = len(r.values)\n",
    "    r.clean_count = len(r.values.dropna())\n",
    "    r.compute_sbacc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, r in runners.items():\n",
    "    print('The benchmark {} started with {} formulae and has valid data for {} formulae'.format(name,r.orig_count,r.clean_count))\n",
    "    r.errors = {}\n",
    "    for e in ['timeout', 'parse error', 'incorrect', 'crash', 'no output']:\n",
    "        s = r.get_error_count(e).sum()\n",
    "        if not pd.isna(s):\n",
    "            r.errors[e] = r.get_error_count(e).sum()\n",
    "    s = pd.Series(r.errors, name='count')\n",
    "    s.index.name = 'error type'\n",
    "    display(s.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_runner(self,cols=['states','acc','time'],\n",
    "                   tool_subset=None, split_col_names=True, col_lev_names=None,\n",
    "                   counts = True):\n",
    "    '''Returns a dataframe with rows indexed by tools in\n",
    "    `tool_subset (or `self.tools.keys()`) and columns by\n",
    "    cols. The values are cummulative sums for respective\n",
    "    tool and column.'''\n",
    "    if tool_subset is None:\n",
    "        tool_subset = self.tools.keys()\n",
    "    name = self.name\n",
    "    name = name.replace('ltl3dra','ltl-gux')\n",
    "    if counts:\n",
    "        name = '{} ({})'.format(name,self.clean_count)\n",
    "    col_names = ['{}_{}'.format(name,c) for c in cols]\n",
    "    df = pd.DataFrame(columns=col_names,index=tool_subset)\n",
    "    for col in cols:\n",
    "        df['{}_{}'.format(name,col)] = self.cummulative(col).map(lambda x: '%0.0f' % x)\n",
    "    if split_col_names:\n",
    "        res = split_cols(df,axis=1,symbol='_',names=col_lev_names)\n",
    "    else:\n",
    "        res = df\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(compute_runner(r).head())\n",
    "display(compute_runner(r,split_col_names=False).head())\n",
    "compute_runner(r,col_lev_names=['source','fragment','metric']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "order = [\n",
    "    ('literature','full'),\n",
    "    ('literature','ltl3dra'),\n",
    "    ('random','full'),\n",
    "    ('random','ltl3dra'),\n",
    "    ('random','fg'),\n",
    "]\n",
    "for o in order:\n",
    "    data.append(compute_runner(runners['{}_{}'.format(o[0],o[1])]))\n",
    "res = pd.concat(data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_acc(acc,sb=False):\n",
    "    acc = acc.replace('TGBA','TGB').replace('NBA','SB')\n",
    "    acc = acc.replace('DPA','DTPA').replace('DTPA','TP')\n",
    "    acc = acc.replace('DSRA','SR').replace('DTGRA','TGR')\n",
    "    acc = acc.replace('DTELA','TEL').replace('TEL.TP','TEL.TEL')\n",
    "    if sb:\n",
    "        acc = re.sub(r'T([^T]+$)', r'S\\1', acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_tools(tool):\n",
    "    tool = tool.replace('ltl2dstar(NBA)',\n",
    "                        '\\parbox[c]{1.3cm}{\\centering ltl2dstar NBA}')\n",
    "    tool = tool.replace('Spot',\n",
    "                        #'\\rotatebox[origin=c]{90}{Spot (autfilt)}')\n",
    "                        '\\parbox[c]{1.3cm}{\\centering Spot autfilt}')\n",
    "    tool = tool.replace('R3','Rabinizer 3').replace('R4','Rabinizer 4')\n",
    "    return tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_fragment(fr,vertical=False):\n",
    "    fr = fr.replace('full','full LTL')\n",
    "    fr = fr.replace('ltl-gux','\\LTLGUX')\n",
    "    fr = fr.replace('ltl3dra','\\LTLGUX')\n",
    "    fr = fr.replace('fg','\\FG').replace('(','[$').replace(')','$]')\n",
    "    if vertical:\n",
    "        fr = '\\rotatebox[origin=c]{90}{' + fr + '}'\n",
    "    return fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_index(df, columns=True, cross=False,\n",
    "                  inplace=False, vertical=False,\n",
    "                  sb=False):\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "    if cross:\n",
    "        i = [(fix_tools(t[0]),t[1],fix_acc(t[2],sb),t[3]) for t in df.index.values]\n",
    "    else:\n",
    "        i = [(fix_tools(t[0]),t[1],fix_acc(t[2],sb)) for t in df.index.values]\n",
    "    df.index=pd.MultiIndex.from_tuples(i)\n",
    "    if columns:\n",
    "        if cross:\n",
    "            ci = [(fix_fragment(t[0],vertical),t[1]) for t in df.columns.values]\n",
    "        else:\n",
    "            ci = [(t[0],fix_fragment(t[1]),t[2]) for t in df.columns.values]\n",
    "        df.columns=pd.MultiIndex.from_tuples(ci)\n",
    "    if not inplace:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_type_lines(filename,Safra=True,vertical=False,end=None):\n",
    "    cline = '\\cmidrule[\\lightrulewidth]{2-'+ str(end) +'}' \\\n",
    "        if vertical else '\\midrule'\n",
    "    todo = [(r'(\\\\multirow\\{2\\}\\{\\*\\}\\{ltl2dpa\\})',''),\n",
    "            (r'(\\\\multirow\\{3\\}\\{\\*\\}\\{ltl2dstar\\})','')]\n",
    "    if not Safra:\n",
    "        todo = [todo[0]]\n",
    "    if vertical:\n",
    "        todo = [(r\"&\\s+\"+t[0], ' & ') for t in todo]\n",
    "    for rplc, pref in todo:\n",
    "        with open(filename) as f:\n",
    "            lines = f.read()\n",
    "            lines = re.sub(rplc,cline + pref + r'\\1',lines)\n",
    "        with open(filename,\"w\") as f1:\n",
    "            f1.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lines(filename, end=12, vertical=False):\n",
    "    end = str(end)\n",
    "    todo = [(r\"(\\\\multirow\\{2\\}\\{\\*\\}\\{ltl2dpa\\})\",1,''),\n",
    "        (r\"(& \\\\multirow\\{2\\}\\{\\*\\}\\{Spot\\})\",2,'')]\n",
    "    if vertical:\n",
    "        todo = [(r\"&\\s+\"+t[0],t[1]+1, ' & ') for t in todo]\n",
    "    for rplc, start, pref in todo:\n",
    "        with open(filename) as f:\n",
    "            lines = f.read()\n",
    "        lines = re.sub(rplc,\n",
    "                       \"\\cmidrule{\" +\n",
    "                       \"{}-{}\".format(start,end) +\n",
    "                       \"}\" + pref + r\"\\1\",\n",
    "                       lines)\n",
    "        with open(filename,\"w\") as f1:\n",
    "            f1.write(lines)\n",
    "    with open(filename) as f:\n",
    "        lines = f.read()\n",
    "    lines = lines.replace('cline','cmidrule')\n",
    "    lines = lines.replace('$nan$','---')\n",
    "    if vertical:\n",
    "        rplc = \"\\cmidrule{1-\" + str(end) + \"}\"\n",
    "        lines = lines.replace(rplc,\"\\midrule[\\heavyrulewidth]\")\n",
    "    # Remove cmidrules in front of midrule\n",
    "    lines = re.sub(r\"(\\\\cmidrule\\{\\d+-\\d+\\}\\n?)*\\\\midrule\\[\\\\heavyrulewidth\\](\\s*\\n*\\s*\\\\cmidrule\\{\\d+-\\d+\\}\\s*\\n?)*\", \"\\\\midrule[\\\\heavyrulewidth] \", lines)\n",
    "    lines = re.sub(r\"(\\\\cmidrule\\{\\d+-\\d+\\}\\s*\\n?)*(\\\\cmidrule\\[\\\\lightrulewidth\\]\\{\\d+-\\d+\\})(\\s*\\n*\\s*\\\\cmidrule\\{\\d+-\\d+\\}\\s*\\n?)*\", r\"\\2 \", lines)\n",
    "    with open(filename,\"w\") as f1:\n",
    "        f1.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_table(filename):\n",
    "    setup = '''\\\\newcolumntype{a}{>{\\\\columncolor{blue!20}}r}\n",
    "\\\\newcolumntype{b}{>{\\\\columncolor{blue!20}}c}\n",
    "\\\\setlength{\\\\aboverulesep}{0pt}\n",
    "\\\\setlength{\\\\belowrulesep}{0pt}\n",
    "\\\\setlength{\\\\extrarowheight}{.75ex}\n",
    "\\\\setlength{\\\\heavyrulewidth}{2pt}\n",
    "\\\\setlength{\\\\lightrulewidth}{1.2pt}\n",
    "\\\\def\\\\high{\\\\cellcolor{darkgreen!40}}\n",
    "'''\n",
    "    with open(filename) as f:\n",
    "        lines = f.read()\n",
    "    lines = fix_header_colors(lines)\n",
    "    with open(filename,\"w\") as f1:\n",
    "        f1.write(setup + lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heading(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.read()\n",
    "    lines = re.sub(r\"(\\s+)&\\s+&\\s+&\\s+states\", \n",
    "        r\"\\1main tool & intermediate & acc & states\",\n",
    "        lines)\n",
    "    lines = re.sub(r\"(\\s+)&\\s+&\\s+&\\s+&\\s+0\", \n",
    "        r\"\\1main tool & intermediate & acc & \\# & 0\",\n",
    "        lines)\n",
    "    with open(filename,\"w\") as f1:\n",
    "        f1.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_header_colors(lines):\n",
    "    lines = lines.replace('{c}','{b}',1)\n",
    "    i = lines.find('{c}')\n",
    "    return lines[:i+1] + lines[i+1:].replace('{c}','{b}',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cummulative_to_latex(res,file,transpose=False,color=True):\n",
    "    if transpose:\n",
    "        res = res.T\n",
    "    col_f = 'ccr'\n",
    "    color_type = 'a' if color else 'r'\n",
    "    for i in range(len(res.columns)//3):\n",
    "        if i % 2 == 0:\n",
    "            col_f += color_type*3\n",
    "        else:\n",
    "            col_f += 'rrr'\n",
    "    res = res\n",
    "    res.to_latex(buf=open(file,'w'), multirow=True,\n",
    "         escape=False, na_rep='---',\n",
    "         float_format=lambda x: '$' + '%0.0f' % x + '$',\n",
    "         column_format=col_f, multicolumn_format='c')\n",
    "    if color:\n",
    "        color_table(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_min(data):\n",
    "    return ['\\high ${:0.0f}$'.format(m) if \n",
    "            m == data.min() else m for m in data]\n",
    "\n",
    "def high_max(data):\n",
    "    return ['\\high ${:0.0f}$'.format(m) if \n",
    "            m == data.max() else m for m in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sort_by_tools(res,tool_order)\n",
    "res = split_cols(res,axis=0,symbol='/')\n",
    "shorten_index(res,inplace=True)\n",
    "sorted_all = res.astype(float).apply(high_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative = [('random','rand'),('literature','lit')]\n",
    "for long, short in cumulative:\n",
    "    filename = 'cum_{}.tex'.format(short)\n",
    "    cummulative_to_latex(sorted_all[long], file=filename)\n",
    "    # We need to measure the # of columns in the LaTeX table\n",
    "    length = len(sorted_all[long].columns) +\\\n",
    "             len(sorted_all[long].index.levels)\n",
    "    fix_lines(filename,length)\n",
    "    add_type_lines(filename)\n",
    "    make_heading(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tool `t1` wins against `t2` in the comparison also if `t2` fails and `t1` does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cross(df,victories=True):\n",
    "    df = split_cols(df,axis=0,symbol='/')  \n",
    "    df = df.T.reset_index(drop=True).T\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index(['level_0','level_1','level_2'],\n",
    "                      append=True)\n",
    "    df = df.reorder_levels([1,2,3,0])\n",
    "    df.index.names = ['','','','']\n",
    "    if victories:\n",
    "        cols = list(df.columns)\n",
    "        cols[len(cols)-1] = 'V'\n",
    "        df.columns = cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_to_latex(res, file='cross.tex', color=True,\n",
    "                   vertical=False):\n",
    "    col_f = 'cccrr' if vertical else 'ccrr'\n",
    "    color_type = 'a' if color else 'r'\n",
    "    for i in range(len(res.columns)):\n",
    "        if i % 2 == 0:\n",
    "            col_f += color_type\n",
    "        else:\n",
    "            col_f += 'r'\n",
    "    res = res\n",
    "    res.to_latex(buf=open(file,'w'), multirow=True,\n",
    "        escape=False,na_rep='---', \n",
    "        float_format=lambda x: '$' + '%0.0f' % x + '$',\n",
    "        column_format=col_f,multicolumn_format='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cross(runners_base, tools, \n",
    "                 fragments=['full','ltl3dra'],\n",
    "                 cols=['states','acc'],\n",
    "                 vertical=False, merge_in_latex=True,\n",
    "                 filename='cross.tex', latex=True):   \n",
    "    def to_latex(table, filename=filename, vertical=False):\n",
    "        table = table.copy()\n",
    "        if vertical:\n",
    "            data = []\n",
    "            for k in table.index.levels[0]:\n",
    "                data.append(\n",
    "                    pd.DataFrame(table.loc[k,'V']).\\\n",
    "                    apply(high_max))\n",
    "                vict = pd.concat(data,\n",
    "                    keys=table.index.levels[0])\n",
    "            table.loc[:,'V'] = vict\n",
    "        else:\n",
    "            table.loc(axis=1)[:,'V'] = \\\n",
    "                table.loc(axis=1)[:,'V'].apply(high_max)\n",
    "        cross_to_latex(table, file=filename, \n",
    "                       vertical=vertical)\n",
    "        end = len(table.columns) + len(table.index.levels)\n",
    "        add_type_lines(filename, Safra=False, \n",
    "                       vertical=vertical, end=end)\n",
    "        fix_lines(filename, end, vertical)\n",
    "        color_table(filename)\n",
    "        make_heading(filename)\n",
    "    \n",
    "    state_based = 'sb_states' in cols\n",
    "    data = []\n",
    "    for fr in fragments:\n",
    "        r = runners['{}_{}'.format(runners_base,fr)]\n",
    "        res = r.cross_compare(tools=tools,props=cols)\n",
    "        cross = prepare_cross(res)\n",
    "        data.append(cross)\n",
    "        if latex and not merge_in_latex:\n",
    "            table = pd.concat([cross], axis=1, keys=[fr])\n",
    "            table = shorten_index(table,cross=True,\n",
    "                        columns=False,inplace=False,\n",
    "                        sb=state_based)\n",
    "            fr_name = '{}_{}.tex'.format(filename[:-4],fr)\n",
    "            to_latex(table, fr_name)\n",
    "    table = pd.concat(data, axis=1, keys=fragments)\n",
    "    shorten_index(table, cross=True, inplace=True,\n",
    "                  vertical=vertical,\n",
    "                  sb=state_based)\n",
    "    if vertical:\n",
    "        fragments = [fix_fragment(f, vertical=vertical)\n",
    "                     for f in fragments]\n",
    "        data = [table[f] for f in fragments]\n",
    "        table = pd.concat(data,keys=fragments)\n",
    "    if latex and merge_in_latex:\n",
    "        to_latex(table,filename,vertical)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = [t for t in tool_order if\n",
    "          'LTL3DRA' in t or\n",
    "          'R3' in t or 'R4' in t]\n",
    "parity = [t for t in tool_order if \n",
    "          'ltl2dpa' in t or 'ltl2tgba' in t]\n",
    "ltl2dstar = [t for t in tool_order if 'ltl2dstar' in t]\n",
    "spot = [t for t in tool_order if \n",
    "        t.startswith('Spot') or\n",
    "        'ltl2tgba' in t]\n",
    "Safra_sel = [t for t in tool_order if \n",
    "           ('Spot/' in t and '/TGBA' in t) or\n",
    "           'ltl2dstar/' in t or \n",
    "           'ltl2tgba' in t]\n",
    "Rabin = [t for t in tool_order if \n",
    "           'ltl2tgba' in t or\n",
    "           ('/DSRA' in t and 'R3' not in t) or\n",
    "           'ltl2dpa' in t]\n",
    "best = [t for t in tool_order if \n",
    "           'ltl2tgba' in t or\n",
    "           'R4//DTGRA' in t or\n",
    "           'ltl2dpa/ldba' in t or\n",
    "           'LTL3TELA' in t]\n",
    "toolsets = {\n",
    "    'direct' : direct,\n",
    "    'ltl2dstar' : ltl2dstar,\n",
    "    'spot' : spot,\n",
    "    'parity' : parity,\n",
    "    'best' : best\n",
    "}\n",
    "toolsets_sbacc = {\n",
    "    'Safra_sel' : Safra_sel,\n",
    "    'Rabin' : Rabin,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, tools in toolsets.items():\n",
    "    filename = 'cross_lit_{}.tex'.format(name)\n",
    "    create_cross('literature', tools, \n",
    "                 filename=filename, merge_in_latex=True,\n",
    "                 vertical=True)\n",
    "for name, tools in toolsets_sbacc.items():\n",
    "    filename = 'cross_lit_{}.tex'.format(name)\n",
    "    create_cross('literature', tools, cols=['sb_states','acc'],\n",
    "                 filename=filename, merge_in_latex=True,\n",
    "                 vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, tools in toolsets.items():\n",
    "    filename = 'cross_rand_{}.tex'.format(name)\n",
    "    create_cross('random', tools, \n",
    "                 filename=filename, merge_in_latex=True,\n",
    "                 vertical=True,fragments=['full','ltl3dra','fg'])\n",
    "for name, tools in toolsets_sbacc.items():\n",
    "    filename = 'cross_rand_{}.tex'.format(name)\n",
    "    create_cross('random', tools, cols=['sb_states','acc'],\n",
    "                 filename=filename, merge_in_latex=True,\n",
    "                 vertical=True,fragments=['full','ltl3dra','fg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = runners['literature_ltl3dra']\n",
    "s = r.values.states.dropna()\n",
    "t1 = 'ltl2tgba//DPA'\n",
    "t2 = 'R4//DSRA'\n",
    "t3 = 'ltl2dpa/ldba/DTPA'\n",
    "val1 = sorted(list(s.loc(axis=1)[t1]))\n",
    "val2 = sorted(list(s.loc(axis=1)[t2]))\n",
    "val3 = sorted(list(s.loc(axis=1)[t3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "import seaborn\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "\n",
    "msize = 12\n",
    "LW=3\n",
    "trace1, = plt.plot(range(0, len(val1)), val1, '-', linewidth=LW, ms = msize, color='green')\n",
    "trace2, = plt.plot(range(0, len(val2)), val2, ':', linewidth=LW, markerfacecolor='none', ms = msize, color='blue')\n",
    "trace3, = plt.plot(range(0, len(val3)), val3, '--', linewidth=LW, ms=msize, color='red')\n",
    "plt.yscale('log')\n",
    "#trace4, = plt.plot(range(0, len(val4)), val4, '-^', markerfacecolor='none', ms=msize)\n",
    "#plt.yscale('log')\n",
    "#plt.setp(color='red')\n",
    "plt.xlabel('n-th fastest benchmark', fontsize=16, labelpad=8)\n",
    "plt.ylabel('time [s]', fontsize=14, labelpad=10)\n",
    "plt.legend([trace1, trace2, trace3],\n",
    "           [t1,t2,t3],\n",
    "            fontsize=14)\n",
    "\n",
    "pp = PdfPages('plot.pdf')\n",
    "pp.savefig(fig, bbox_inches='tight')\n",
    "pp.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "\n",
    "msize = 12\n",
    "LW=3\n",
    "\n",
    "plt.plot(s.index.labels[0],s[t1], '*')\n",
    "plt.plot(s.index.labels[0],s[t2], '*')\n",
    "plt.plot(s.index.labels[0],s[t3], '*')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.cummulative('states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.cummulative('sb_states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.cross_compare(Safra,['sb_states','acc'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
